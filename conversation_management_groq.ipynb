{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eJabNa4ziu8C"
      },
      "outputs": [],
      "source": [
        "# Conversation Management & Classification using Groq API\n",
        "\n",
        "#Assignment Submission by: Sehba Hanief\n",
        "\n",
        "!pip install --upgrade --quiet groq jsonschema\n",
        "import os\n",
        "\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = input(\"ðŸ”‘ Enter your GROQ API key: \")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n"
      ],
      "metadata": {
        "id": "ug3Yn1U3jI0V"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello Groq, can you hear me?\"}]\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05xHmZNUkdt_",
        "outputId": "47ff5e84-bf8d-45e7-98a9-f6884bd01983"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content=\"However, I need to clarify that I'm not Groq, but rather an AI assistant. I'm here to help answer your questions and provide information. If you're referring to Groq, the company is likely a tech firm known for its deep learning processor designs.\", role='assistant', executed_tools=None, function_call=None, reasoning=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationHistory:\n",
        "    def __init__(self, client, summarization_model=\"llama-3.1-8b-instant\"):\n",
        "        self.client = client\n",
        "        self.messages = []\n",
        "        self.run_count = 0\n",
        "        self.summarization_model = summarization_model\n",
        "\n",
        "    def add_message(self, role, content):\n",
        "        self.messages.append({\"role\": role, \"content\": content})\n",
        "        self.run_count += 1\n",
        "\n",
        "    def truncate_by_turns(self, n):\n",
        "        return self.messages[-n*2:]\n",
        "\n",
        "    def truncate_by_chars(self, max_chars):\n",
        "        result, count = [], 0\n",
        "        for msg in reversed(self.messages):\n",
        "            if count + len(msg['content']) > max_chars:\n",
        "                break\n",
        "            result.insert(0, msg)\n",
        "            count += len(msg['content'])\n",
        "        return result\n",
        "\n",
        "    def summarize(self, window_size=6):\n",
        "        window = self.messages[-window_size:]\n",
        "        content = \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in window])\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.summarization_model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Summarize this conversation briefly.\"},\n",
        "                {\"role\": \"user\", \"content\": content}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    def periodic_summarize_and_replace(self, k=3, window_size=6):\n",
        "        if self.run_count % k == 0 and len(self.messages) >= window_size:\n",
        "            summary = self.summarize(window_size)\n",
        "            self.messages = self.messages[:-window_size] + [\n",
        "                {\"role\": \"system\", \"content\": f\"[Summary]: {summary}\"}\n",
        "            ]\n",
        "\n",
        "    def get_history(self):\n",
        "        return self.messages\n"
      ],
      "metadata": {
        "id": "r8ysiUgVkpmf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = ConversationHistory(client)\n",
        "\n",
        "# Simulate a chat\n",
        "samples = [\n",
        "    (\"user\", \"Hi, I am John from Delhi.\"),\n",
        "    (\"assistant\", \"Hello John, how can I help you?\"),\n",
        "    (\"user\", \"I am 25 years old and my email is john@example.com.\"),\n",
        "    (\"assistant\", \"Thanks for sharing your details.\"),\n",
        "    (\"user\", \"My phone number is 9876543210.\"),\n",
        "    (\"assistant\", \"Got it, John.\"),\n",
        "]\n",
        "\n",
        "for role, content in samples:\n",
        "    history.add_message(role, content)\n",
        "    history.periodic_summarize_and_replace(k=3)\n",
        "\n",
        "print(\"=== Full History ===\")\n",
        "print(history.get_history())\n",
        "\n",
        "print(\"\\n=== Truncated by last 2 turns ===\")\n",
        "print(history.truncate_by_turns(2))\n",
        "\n",
        "print(\"\\n=== Truncated by 80 chars ===\")\n",
        "print(history.truncate_by_chars(80))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA90aLoJktHQ",
        "outputId": "40726821-8691-48c7-ec57-e60cf262dac0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Full History ===\n",
            "[{'role': 'system', 'content': '[Summary]: There is no conversation to summarize as the conversation only consisted of you playing the role of John sharing your details with me, and I responding accordingly.'}]\n",
            "\n",
            "=== Truncated by last 2 turns ===\n",
            "[{'role': 'system', 'content': '[Summary]: There is no conversation to summarize as the conversation only consisted of you playing the role of John sharing your details with me, and I responding accordingly.'}]\n",
            "\n",
            "=== Truncated by 80 chars ===\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from jsonschema import validate\n",
        "\n",
        "EXTRACTION_SCHEMA = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": \"string\"},\n",
        "        \"email\": {\"type\": \"string\"},\n",
        "        \"phone\": {\"type\": \"string\"},\n",
        "        \"location\": {\"type\": \"string\"},\n",
        "        \"age\": {\"type\": \"string\"},\n",
        "    },\n",
        "    \"required\": [\"name\", \"email\", \"phone\", \"location\", \"age\"]\n",
        "}\n",
        "\n",
        "def extract_info(chat_text):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"Extract the following fields and return them strictly as JSON: \"\n",
        "                           \"name, email, phone, location, age.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Chat: {chat_text}\\n\\nReturn only valid JSON with those fields.\"\n",
        "            }\n",
        "        ],\n",
        "        response_format={\"type\": \"json_object\"}  # forces JSON output\n",
        "    )\n",
        "    return json.loads(response.choices[0].message.content)\n",
        "\n",
        "\n",
        "def validate_extraction(data):\n",
        "    try:\n",
        "        validate(instance=data, schema=EXTRACTION_SCHEMA)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        return str(e)\n"
      ],
      "metadata": {
        "id": "ylx4wQIwkyGg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_chats = [\n",
        "    \"Hi, I am John Doe from Delhi, 25 years old. My email is john@example.com and my phone is 9876543210.\",\n",
        "    \"My name is Sarah Khan, 30 years old, living in Mumbai. Contact me at sarah@gmail.com, phone 9123456789.\",\n",
        "    \"Hello, this is Mike from Bangalore, age 22. You can reach me at mike22@yahoo.com, phone number 9988776655.\"\n",
        "]\n",
        "\n",
        "for chat in sample_chats:\n",
        "    extracted = extract_info(chat)\n",
        "    print(\"\\nChat:\", chat)\n",
        "    print(\"Extracted:\", extracted)\n",
        "    print(\"Validation:\", validate_extraction(extracted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJKKsU7Uk2DV",
        "outputId": "fcf839cf-f23f-4a91-cd89-661034f4373d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chat: Hi, I am John Doe from Delhi, 25 years old. My email is john@example.com and my phone is 9876543210.\n",
            "Extracted: {'name': 'John Doe', 'email': 'john@example.com', 'phone': '9876543210', 'location': 'Delhi', 'age': 25}\n",
            "Validation: 25 is not of type 'string'\n",
            "\n",
            "Failed validating 'type' in schema['properties']['age']:\n",
            "    {'type': 'string'}\n",
            "\n",
            "On instance['age']:\n",
            "    25\n",
            "\n",
            "Chat: My name is Sarah Khan, 30 years old, living in Mumbai. Contact me at sarah@gmail.com, phone 9123456789.\n",
            "Extracted: {'name': 'Sarah Khan', 'email': 'sarah@gmail.com', 'phone': '9123456789', 'location': 'Mumbai', 'age': 30}\n",
            "Validation: 30 is not of type 'string'\n",
            "\n",
            "Failed validating 'type' in schema['properties']['age']:\n",
            "    {'type': 'string'}\n",
            "\n",
            "On instance['age']:\n",
            "    30\n",
            "\n",
            "Chat: Hello, this is Mike from Bangalore, age 22. You can reach me at mike22@yahoo.com, phone number 9988776655.\n",
            "Extracted: {'name': 'Mike', 'email': 'mike22@yahoo.com', 'phone': '9988776655', 'location': 'Bangalore', 'age': '22'}\n",
            "Validation: True\n"
          ]
        }
      ]
    }
  ]
}